/Users/oliverclive-griffin/personal/transformer-from-scratch/train.py:66: UserWarning: The operator 'aten::roll' is not currently supported on the MPS backend and will fall back to run on the CPU. This may have performance implications. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/mps/MPSFallback.mm:11.)
  y = torch.roll(x, -1, dims=-1)
epoch 0 batch 0 loss 4.117526054382324
epoch 0 batch 1 loss 4.060884475708008
epoch 0 batch 2 loss 3.991529941558838
epoch 0 batch 3 loss 3.9047799110412598
epoch 0 batch 4 loss 3.7913355827331543
epoch 0 batch 5 loss 3.687112808227539
epoch 0 batch 6 loss 3.626671552658081
epoch 0 batch 7 loss 3.5951404571533203
epoch 0 batch 8 loss 3.452561140060425
epoch 0 batch 9 loss 3.4173710346221924
epoch 0 batch 10 loss 3.3510851860046387
epoch 0 batch 11 loss 3.3356151580810547
epoch 0 batch 12 loss 3.301809549331665
epoch 0 batch 13 loss 3.2173943519592285
epoch 0 batch 14 loss 3.189913749694824
epoch 0 batch 15 loss 3.121474504470825
epoch 0 batch 16 loss 3.1421055793762207
epoch 0 batch 17 loss 3.0836496353149414
epoch 0 batch 18 loss 3.068345069885254
epoch 0 batch 19 loss 3.051506996154785
epoch 0 batch 20 loss 3.0508627891540527
epoch 0 batch 21 loss 3.002605438232422
epoch 0 batch 22 loss 2.964756965637207
epoch 0 batch 23 loss 3.0018703937530518
epoch 0 batch 24 loss 2.955498456954956
epoch 0 batch 25 loss 2.939633369445801
epoch 0 batch 26 loss 2.947312831878662
epoch 0 batch 27 loss 2.8506381511688232
epoch 0 batch 28 loss 2.881326675415039
epoch 0 batch 29 loss 2.867504358291626
epoch 0 batch 30 loss 2.855459690093994
epoch 0 batch 31 loss 2.9219725131988525
epoch 0 batch 32 loss 2.8059611320495605
epoch 0 batch 33 loss 2.864084243774414
epoch 0 batch 34 loss 2.7790215015411377
epoch 0 batch 35 loss 2.7219934463500977
epoch 0 batch 36 loss 2.7632410526275635
epoch 0 batch 37 loss 2.740532875061035
epoch 0 batch 38 loss 2.7516889572143555
epoch 0 batch 39 loss 2.7459897994995117
epoch 0 batch 40 loss 2.7778522968292236
epoch 0 batch 41 loss 2.6701064109802246
epoch 0 batch 42 loss 2.681760787963867
epoch 0 batch 43 loss 2.7421700954437256
epoch 0 batch 44 loss 2.728808879852295
epoch 0 batch 45 loss 2.716831684112549
epoch 0 batch 46 loss 2.6592719554901123
epoch 0 batch 47 loss 2.656001091003418
epoch 0 batch 48 loss 2.7078609466552734
epoch 0 batch 49 loss 2.725581169128418
epoch 0 batch 50 loss 2.639517307281494
epoch 0 batch 51 loss 2.7088451385498047
epoch 0 batch 52 loss 2.714141845703125
epoch 0 batch 53 loss 2.6503803730010986
epoch 0 batch 54 loss 2.651390552520752
epoch 0 batch 55 loss 2.7485737800598145
epoch 0 batch 56 loss 2.713001251220703
epoch 0 batch 57 loss 2.6358745098114014
epoch 0 batch 58 loss 2.5615057945251465
epoch 0 batch 59 loss 2.597018241882324
epoch 0 batch 60 loss 2.5973992347717285
epoch 0 batch 61 loss 2.6101014614105225
epoch 0 batch 62 loss 2.584555149078369
epoch 0 batch 63 loss 2.6516761779785156
epoch 0 batch 64 loss 2.6049509048461914
epoch 0 batch 65 loss 2.6256799697875977
epoch 0 batch 66 loss 2.648632526397705
epoch 0 batch 67 loss 2.573953151702881
epoch 0 batch 68 loss 2.5945029258728027
epoch 0 batch 69 loss 2.6280829906463623
epoch 0 batch 70 loss 2.6148476600646973
epoch 0 batch 71 loss 2.50931715965271
epoch 0 batch 72 loss 2.565591335296631
epoch 0 batch 73 loss 2.61783504486084
epoch 0 batch 74 loss 2.549168109893799
epoch 0 batch 75 loss 2.525858163833618
epoch 0 batch 76 loss 2.5798122882843018
epoch 0 batch 77 loss 2.6160972118377686
epoch 0 batch 78 loss 2.5787994861602783
epoch 0 batch 79 loss 2.552609920501709
epoch 0 batch 80 loss 2.578845739364624
epoch 0 batch 81 loss 2.5833358764648438
epoch 0 batch 82 loss 2.6002039909362793
epoch 0 batch 83 loss 2.532775402069092
epoch 0 batch 84 loss 2.5803732872009277
epoch 0 batch 85 loss 2.536102294921875
epoch 0 batch 86 loss 2.5164828300476074
epoch 0 batch 87 loss 2.587606430053711
epoch 0 batch 88 loss 2.5853824615478516
epoch 0 batch 89 loss 2.5835165977478027
epoch 0 batch 90 loss 2.5712525844573975
epoch 0 batch 91 loss 2.517737865447998
epoch 0 batch 92 loss 2.5666723251342773
epoch 0 batch 93 loss 2.552549362182617
epoch 0 batch 94 loss 2.5391199588775635
epoch 0 batch 95 loss 2.579566717147827
epoch 0 batch 96 loss 2.5755715370178223
epoch 0 batch 97 loss 2.516108989715576
epoch 0 batch 98 loss 2.5653061866760254
epoch 0 batch 99 loss 2.6090736389160156
epoch 0 batch 100 loss 2.523392677307129
epoch 0 batch 101 loss 2.519317150115967
epoch 0 batch 102 loss 2.6013870239257812
epoch 0 batch 103 loss 2.4629921913146973
epoch 0 batch 104 loss 2.4711456298828125
epoch 0 batch 105 loss 2.6274595260620117
epoch 0 batch 106 loss 2.5132036209106445
epoch 0 batch 107 loss 2.6224918365478516
epoch 0 batch 108 loss 2.55818510055542
epoch 0 batch 109 loss 2.508218765258789
epoch 0 batch 110 loss 2.527338743209839
epoch 0 batch 111 loss 2.534215211868286
epoch 0 batch 112 loss 2.546745777130127
epoch 0 batch 113 loss 2.557924747467041
epoch 0 batch 114 loss 2.528181552886963
epoch 0 batch 115 loss 2.476691961288452
epoch 0 batch 116 loss 2.497504949569702
epoch 0 batch 117 loss 2.5366933345794678
epoch 0 batch 118 loss 2.575190544128418
epoch 0 batch 119 loss 2.5953032970428467
epoch 0 batch 120 loss 2.5519676208496094
epoch 0 batch 121 loss 2.4888291358947754
epoch 0 batch 122 loss 2.5514721870422363
epoch 0 batch 123 loss 2.5554399490356445
epoch 0 batch 124 loss 2.5414042472839355
epoch 0 batch 125 loss 2.570650100708008
epoch 0 batch 126 loss 2.524397373199463
epoch 0 batch 127 loss 2.5286903381347656
epoch 0 batch 128 loss 2.5042178630828857
epoch 0 batch 129 loss 2.5560383796691895
epoch 0 batch 130 loss 2.547806739807129
epoch 0 batch 131 loss 2.491502046585083
epoch 0 batch 132 loss 2.5577425956726074
epoch 0 batch 133 loss 2.634821653366089
epoch 0 batch 134 loss 2.506730556488037
epoch 0 batch 135 loss 2.564728260040283
epoch 0 batch 136 loss 2.526392698287964
epoch 0 batch 137 loss 2.502596378326416
epoch 0 batch 138 loss 2.5076208114624023
epoch 0 batch 139 loss 2.5247485637664795
epoch 0 batch 140 loss 2.5426435470581055
epoch 0 batch 141 loss 2.5072946548461914
epoch 0 batch 142 loss 2.4782800674438477
epoch 0 batch 143 loss 2.4806666374206543
epoch 0 batch 144 loss 2.6119766235351562
epoch 0 batch 145 loss 2.5092830657958984
epoch 0 batch 146 loss 2.442188262939453
epoch 0 batch 147 loss 2.5152320861816406
epoch 0 batch 148 loss 2.5966591835021973
epoch 0 batch 149 loss 2.4893956184387207
epoch 0 batch 150 loss 2.4863996505737305
epoch 0 batch 151 loss 2.4892020225524902
epoch 0 batch 152 loss 2.499410390853882
epoch 0 batch 153 loss 2.5014967918395996
epoch 0 batch 154 loss 2.480340003967285
epoch 0 batch 155 loss 2.4745283126831055
epoch 0 batch 156 loss 2.532782554626465
epoch 0 batch 157 loss 2.564574956893921
epoch 0 batch 158 loss 2.508654832839966
epoch 0 batch 159 loss 2.5328826904296875
epoch 0 batch 160 loss 2.5036420822143555
epoch 0 batch 161 loss 2.5545055866241455
epoch 0 batch 162 loss 2.514249324798584
epoch 0 batch 163 loss 2.476680040359497
epoch 0 batch 164 loss 2.449375867843628
epoch 0 batch 165 loss 2.501556873321533
epoch 0 batch 166 loss 2.545950412750244
epoch 0 batch 167 loss 2.5457968711853027
epoch 0 batch 168 loss 2.483180522918701
epoch 0 batch 169 loss 2.5201168060302734
epoch 0 batch 170 loss 2.4682130813598633
epoch 0 batch 171 loss 2.5644469261169434
epoch 0 batch 172 loss 2.5479483604431152
epoch 0 batch 173 loss 2.485826253890991
epoch 0 batch 174 loss 2.5322365760803223
epoch 0 batch 175 loss 2.45090389251709
epoch 0 batch 176 loss 2.507570743560791
epoch 0 batch 177 loss 2.519782066345215
epoch 0 batch 178 loss 2.595186233520508
epoch 0 batch 179 loss 2.489299774169922
epoch 0 batch 180 loss 2.4593539237976074
epoch 0 batch 181 loss 2.5197067260742188
epoch 0 batch 182 loss 2.5056333541870117
epoch 0 batch 183 loss 2.485980987548828
epoch 0 batch 184 loss 2.4870681762695312
epoch 0 batch 185 loss 2.5103211402893066
epoch 0 batch 186 loss 2.481445550918579
epoch 0 batch 187 loss 2.523236036300659
epoch 0 batch 188 loss 2.481718063354492
epoch 0 batch 189 loss 2.5126953125
epoch 0 batch 190 loss 2.540013313293457
epoch 0 batch 191 loss 2.5078911781311035
epoch 0 batch 192 loss 2.475161552429199
epoch 0 batch 193 loss 2.521890163421631
epoch 0 batch 194 loss 2.478350877761841
epoch 0 batch 195 loss 2.5264928340911865
epoch 0 batch 196 loss 2.5355613231658936
epoch 0 batch 197 loss 2.503866672515869
epoch 0 batch 198 loss 2.513955593109131
epoch 0 batch 199 loss 2.532487392425537
epoch 0 batch 200 loss 2.4872403144836426
epoch 0 batch 201 loss 2.5220165252685547
epoch 0 batch 202 loss 2.5813989639282227
epoch 0 batch 203 loss 2.526724338531494
epoch 0 batch 204 loss 2.522339344024658
epoch 0 batch 205 loss 2.4639039039611816
epoch 0 batch 206 loss 2.5159502029418945
epoch 0 batch 207 loss 2.497025489807129
epoch 0 batch 208 loss 2.4820995330810547
epoch 0 batch 209 loss 2.4800686836242676
epoch 0 batch 210 loss 2.4920129776000977
epoch 0 batch 211 loss 2.484924077987671
epoch 0 batch 212 loss 2.6048154830932617
epoch 0 batch 213 loss 2.4650919437408447
epoch 0 batch 214 loss 2.465618371963501
epoch 0 batch 215 loss 2.5209131240844727
epoch 0 batch 216 loss 2.483938217163086
epoch 0 batch 217 loss 2.4600656032562256
epoch 0 batch 218 loss 2.5279407501220703
epoch 0 batch 219 loss 2.496678590774536
epoch 0 batch 220 loss 2.5193614959716797
epoch 0 batch 221 loss 2.485097885131836
epoch 0 batch 222 loss 2.5309395790100098
epoch 0 batch 223 loss 2.4600915908813477
epoch 0 batch 224 loss 2.5137276649475098
epoch 0 batch 225 loss 2.4745993614196777
epoch 0 batch 226 loss 2.5111608505249023
epoch 0 batch 227 loss 2.4339489936828613
epoch 0 batch 228 loss 2.4758362770080566
epoch 0 batch 229 loss 2.528348922729492
epoch 0 batch 230 loss 2.496123790740967
epoch 0 batch 231 loss 2.4907565116882324
epoch 0 batch 232 loss 2.5153727531433105
epoch 0 batch 233 loss 2.445319175720215
epoch 0 batch 234 loss 2.509866952896118
epoch 0 batch 235 loss 2.4729409217834473
epoch 0 batch 236 loss 2.4381513595581055
epoch 0 batch 237 loss 2.477818489074707
epoch 0 batch 238 loss 2.6452748775482178
epoch 0 batch 239 loss 2.3934926986694336
epoch 0 batch 240 loss 2.4604005813598633
epoch 0 batch 241 loss 2.4748177528381348
epoch 0 batch 242 loss 2.5099921226501465
epoch 0 batch 243 loss 2.482337713241577
epoch 0 batch 244 loss 2.5154974460601807
epoch 0 batch 245 loss 2.502354860305786
epoch 0 batch 246 loss 2.4875266551971436
epoch 0 batch 247 loss 2.4802281856536865
epoch 0 batch 248 loss 2.4845495223999023
epoch 0 batch 249 loss 2.4595084190368652
epoch 0 batch 250 loss 2.449204206466675
epoch 0 batch 251 loss 2.5106210708618164
epoch 0 batch 252 loss 2.482508897781372
epoch 0 batch 253 loss 2.5185232162475586
epoch 0 batch 254 loss 2.4472885131835938
epoch 0 batch 255 loss 2.5248124599456787
epoch 0 batch 256 loss 2.460564613342285
epoch 0 batch 257 loss 2.490100622177124
epoch 0 batch 258 loss 2.5301637649536133
epoch 0 batch 259 loss 2.420149564743042
epoch 0 batch 260 loss 2.45460844039917
epoch 0 batch 261 loss 2.5090932846069336
epoch 0 batch 262 loss 2.506678581237793
epoch 0 batch 263 loss 2.3976211547851562
epoch 0 batch 264 loss 2.4969210624694824
epoch 0 batch 265 loss 2.461392879486084
epoch 0 batch 266 loss 2.487255334854126
epoch 0 batch 267 loss 2.4944872856140137
epoch 0 batch 268 loss 2.4626612663269043
epoch 0 batch 269 loss 2.5365288257598877
epoch 0 batch 270 loss 2.4312405586242676
epoch 0 batch 271 loss 2.5239930152893066
epoch 0 batch 272 loss 2.4437198638916016
epoch 0 batch 273 loss 2.4540882110595703
epoch 0 batch 274 loss 2.5390868186950684
epoch 0 batch 275 loss 2.5233190059661865
epoch 0 batch 276 loss 2.4376273155212402
epoch 0 batch 277 loss 2.4959874153137207
epoch 0 batch 278 loss 2.4568376541137695
epoch 0 batch 279 loss 2.4945006370544434
epoch 0 batch 280 loss 2.4923717975616455
epoch 0 batch 281 loss 2.4999914169311523
epoch 0 batch 282 loss 2.4774229526519775
epoch 0 batch 283 loss 2.4664764404296875
epoch 0 batch 284 loss 2.577139377593994
epoch 0 batch 285 loss 2.485407590866089
epoch 0 batch 286 loss 2.433926582336426
epoch 0 batch 287 loss 2.53928279876709
epoch 0 batch 288 loss 2.4679837226867676
epoch 0 batch 289 loss 2.5179662704467773
epoch 0 batch 290 loss 2.4936363697052
epoch 0 batch 291 loss 2.495293617248535
epoch 0 batch 292 loss 2.5167555809020996
epoch 0 batch 293 loss 2.4483160972595215
epoch 0 batch 294 loss 2.4808406829833984
epoch 0 batch 295 loss 2.4441637992858887
epoch 0 batch 296 loss 2.552938461303711
epoch 0 batch 297 loss 2.459653854370117
epoch 0 batch 298 loss 2.5013041496276855
epoch 0 batch 299 loss 2.478714942932129
epoch 0 batch 300 loss 2.457180976867676
epoch 0 batch 301 loss 2.4196763038635254
epoch 0 batch 302 loss 2.447246551513672
epoch 0 batch 303 loss 2.5479347705841064
epoch 0 batch 304 loss 2.5153255462646484
epoch 0 batch 305 loss 2.5239310264587402
epoch 0 batch 306 loss 2.444411277770996
epoch 0 batch 307 loss 2.48626708984375
epoch 0 batch 308 loss 2.4372735023498535
epoch 0 batch 309 loss 2.500415325164795
epoch 0 batch 310 loss 2.4616763591766357
epoch 0 batch 311 loss 2.4886951446533203
epoch 0 batch 312 loss 2.4363105297088623
epoch 0 batch 313 loss 2.4952354431152344
epoch 0 batch 314 loss 2.487898111343384
epoch 0 batch 315 loss 2.4037508964538574
epoch 0 batch 316 loss 2.48832106590271
epoch 0 batch 317 loss 2.4694533348083496
epoch 0 batch 318 loss 2.499831438064575
epoch 0 batch 319 loss 2.5279364585876465
epoch 0 batch 320 loss 2.472273826599121
epoch 0 batch 321 loss 2.4454286098480225
epoch 0 batch 322 loss 2.5347697734832764
epoch 0 batch 323 loss 2.504502773284912
epoch 0 batch 324 loss 2.4491279125213623
epoch 0 batch 325 loss 2.4435477256774902
epoch 0 batch 326 loss 2.457463026046753
epoch 0 batch 327 loss 2.4605658054351807
epoch 0 batch 328 loss 2.486506462097168
epoch 0 batch 329 loss 2.5038881301879883
epoch 0 batch 330 loss 2.4287021160125732
epoch 0 batch 331 loss 2.45028018951416
epoch 0 batch 332 loss 2.454751491546631
epoch 0 batch 333 loss 2.4517831802368164
epoch 0 batch 334 loss 2.5529818534851074
epoch 0 batch 335 loss 2.487036943435669
epoch 0 batch 336 loss 2.462318181991577
epoch 0 batch 337 loss 2.5218381881713867
epoch 0 batch 338 loss 2.542520523071289
epoch 0 batch 339 loss 2.4475860595703125
epoch 0 batch 340 loss 2.4456167221069336
epoch 0 batch 341 loss 2.4685797691345215
epoch 0 batch 342 loss 2.416473627090454
epoch 0 batch 343 loss 2.442183256149292
epoch 0 batch 344 loss 2.5045571327209473
epoch 0 batch 345 loss 2.4626312255859375
epoch 0 batch 346 loss 2.5034098625183105
epoch 0 batch 347 loss 2.437462091445923
epoch 0 batch 348 loss 2.439523696899414
epoch 0 batch 349 loss 2.442387580871582
epoch 0 batch 350 loss 2.5213637351989746
epoch 0 batch 351 loss 2.3986077308654785
epoch 0 batch 352 loss 2.4547059535980225
epoch 0 batch 353 loss 2.4183735847473145
epoch 0 batch 354 loss 2.4413161277770996
epoch 0 batch 355 loss 2.464294910430908
epoch 0 batch 356 loss 2.4763782024383545
epoch 0 batch 357 loss 2.464874267578125
epoch 0 batch 358 loss 2.494757890701294
epoch 0 batch 359 loss 2.469787120819092
epoch 0 batch 360 loss 2.4546194076538086
epoch 0 batch 361 loss 2.5004005432128906
epoch 0 batch 362 loss 2.437161445617676
epoch 0 batch 363 loss 2.448739528656006
epoch 0 batch 364 loss 2.5041840076446533
epoch 0 batch 365 loss 2.4972715377807617
epoch 0 batch 366 loss 2.4281234741210938
epoch 0 batch 367 loss 2.4884023666381836
epoch 0 batch 368 loss 2.396942138671875
epoch 0 batch 369 loss 2.453970432281494
epoch 0 batch 370 loss 2.4531760215759277
epoch 0 batch 371 loss 2.4338443279266357
epoch 0 batch 372 loss 2.4545514583587646
epoch 0 batch 373 loss 2.4382247924804688
epoch 0 batch 374 loss 2.4728472232818604
epoch 0 batch 375 loss 2.450515031814575
epoch 0 batch 376 loss 2.5014901161193848
epoch 0 batch 377 loss 2.4576399326324463
epoch 0 batch 378 loss 2.4742112159729004
epoch 0 batch 379 loss 2.4757020473480225
epoch 0 batch 380 loss 2.4768943786621094
epoch 0 batch 381 loss 2.396789073944092
epoch 0 batch 382 loss 2.438656806945801
epoch 0 batch 383 loss 2.5122907161712646
epoch 0 batch 384 loss 2.4179415702819824
epoch 0 batch 385 loss 2.468266010284424
epoch 0 batch 386 loss 2.446397542953491
epoch 0 batch 387 loss 2.4878644943237305
epoch 0 batch 388 loss 2.437765121459961
epoch 0 batch 389 loss 2.467405319213867
epoch 0 batch 390 loss 2.529283046722412
epoch 0 batch 391 loss 2.4695305824279785
epoch 0 batch 392 loss 2.4348649978637695
epoch 0 batch 393 loss 2.4675965309143066
epoch 0 batch 394 loss 2.5103812217712402
epoch 0 batch 395 loss 2.4465017318725586
epoch 0 batch 396 loss 2.4937877655029297
epoch 0 batch 397 loss 2.470155954360962
epoch 0 batch 398 loss 2.4203710556030273
epoch 0 batch 399 loss 2.4529056549072266
epoch 0 batch 400 loss 2.4882094860076904
epoch 0 batch 401 loss 2.4652276039123535
epoch 0 batch 402 loss 2.489043951034546
epoch 0 batch 403 loss 2.4857394695281982
epoch 0 batch 404 loss 2.4269309043884277
epoch 0 batch 405 loss 2.4564833641052246
epoch 0 batch 406 loss 2.4485573768615723
epoch 0 batch 407 loss 2.4052443504333496
epoch 0 batch 408 loss 2.4624223709106445
epoch 0 batch 409 loss 2.4397854804992676
epoch 0 batch 410 loss 2.4205727577209473
epoch 0 batch 411 loss 2.4240622520446777
epoch 0 batch 412 loss 2.4747283458709717
epoch 0 batch 413 loss 2.481039047241211
epoch 0 batch 414 loss 2.42048978805542
epoch 0 batch 415 loss 2.4084630012512207
/Users/oliverclive-griffin/.local/share/virtualenvs/transformer-from-scratch-IzBRPy8T/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
epoch 0 batch 416 loss 2.432128667831421
epoch 0 batch 417 loss 2.3340442180633545
epoch 0 batch 418 loss 2.4682416915893555
epoch 0 batch 419 loss 2.488461494445801
epoch 0 batch 420 loss 2.4601707458496094
epoch 0 batch 421 loss 2.506438732147217
epoch 0 batch 422 loss 2.4967236518859863
epoch 0 batch 423 loss 2.3993515968322754
epoch 0 batch 424 loss 2.414083480834961
epoch 0 batch 425 loss 2.442206859588623
epoch 0 batch 426 loss 2.38293194770813
epoch 0 batch 427 loss 2.454190731048584
epoch 0 batch 428 loss 2.394747495651245
epoch 0 batch 429 loss 2.46433687210083
epoch 0 batch 430 loss 2.424504280090332
epoch 0 batch 431 loss 2.448239803314209
epoch 0 batch 432 loss 2.446320056915283
epoch 0 batch 433 loss 2.361203908920288
epoch 0 batch 434 loss 2.4783952236175537
epoch 0
<>wo,ehieuha:i eaoiaoah<>
epoch 1 batch 0 loss 2.349811315536499
epoch 1 batch 1 loss 2.405330181121826
epoch 1 batch 2 loss 2.4047698974609375
epoch 1 batch 3 loss 2.3909947872161865
epoch 1 batch 4 loss 2.4060397148132324
epoch 1 batch 5 loss 2.386497735977173
epoch 1 batch 6 loss 2.4385581016540527
epoch 1 batch 7 loss 2.434410572052002
epoch 1 batch 8 loss 2.3716564178466797
epoch 1 batch 9 loss 2.4111413955688477
epoch 1 batch 10 loss 2.4843711853027344
epoch 1 batch 11 loss 2.452531099319458
epoch 1 batch 12 loss 2.464816093444824
epoch 1 batch 13 loss 2.3925259113311768
epoch 1 batch 14 loss 2.4196465015411377
epoch 1 batch 15 loss 2.3860836029052734
epoch 1 batch 16 loss 2.4865365028381348
epoch 1 batch 17 loss 2.411712408065796
epoch 1 batch 18 loss 2.444674015045166
epoch 1 batch 19 loss 2.432967185974121
epoch 1 batch 20 loss 2.516707181930542
epoch 1 batch 21 loss 2.417395830154419
epoch 1 batch 22 loss 2.5072898864746094
epoch 1 batch 23 loss 2.494128942489624
epoch 1 batch 24 loss 2.4530410766601562
epoch 1 batch 25 loss 2.4229183197021484
epoch 1 batch 26 loss 2.4229931831359863
epoch 1 batch 27 loss 2.4249496459960938
epoch 1 batch 28 loss 2.393455982208252
epoch 1 batch 29 loss 2.4114158153533936
epoch 1 batch 30 loss 2.4616775512695312
epoch 1 batch 31 loss 2.562817096710205
epoch 1 batch 32 loss 2.434833526611328
epoch 1 batch 33 loss 2.4076967239379883
epoch 1 batch 34 loss 2.4129087924957275
epoch 1 batch 35 loss 2.4527528285980225
epoch 1 batch 36 loss 2.3927764892578125
epoch 1 batch 37 loss 2.416354179382324
epoch 1 batch 38 loss 2.434516429901123
epoch 1 batch 39 loss 2.4568142890930176
epoch 1 batch 40 loss 2.509121894836426
epoch 1 batch 41 loss 2.396702766418457
epoch 1 batch 42 loss 2.396845817565918
epoch 1 batch 43 loss 2.4349026679992676
epoch 1 batch 44 loss 2.4490976333618164
epoch 1 batch 45 loss 2.3943238258361816
epoch 1 batch 46 loss 2.4556596279144287
epoch 1 batch 47 loss 2.434715747833252
epoch 1 batch 48 loss 2.3923439979553223
epoch 1 batch 49 loss 2.3910512924194336
epoch 1 batch 50 loss 2.3890092372894287
epoch 1 batch 51 loss 2.3985676765441895
epoch 1 batch 52 loss 2.394458293914795
epoch 1 batch 53 loss 2.3440942764282227
epoch 1 batch 54 loss 2.4280641078948975
epoch 1 batch 55 loss 2.4759435653686523
epoch 1 batch 56 loss 2.427969455718994
epoch 1 batch 57 loss 2.429109573364258
epoch 1 batch 58 loss 2.4055206775665283
epoch 1 batch 59 loss 2.3765311241149902
epoch 1 batch 60 loss 2.409215211868286
epoch 1 batch 61 loss 2.3263583183288574
epoch 1 batch 62 loss 2.3700318336486816
epoch 1 batch 63 loss 2.42575740814209
epoch 1 batch 64 loss 2.385115623474121
epoch 1 batch 65 loss 2.4184861183166504
epoch 1 batch 66 loss 2.4047036170959473
epoch 1 batch 67 loss 2.4010987281799316
epoch 1 batch 68 loss 2.4574427604675293
epoch 1 batch 69 loss 2.385439395904541
epoch 1 batch 70 loss 2.3818678855895996
epoch 1 batch 71 loss 2.38446044921875
epoch 1 batch 72 loss 2.413849115371704
epoch 1 batch 73 loss 2.3587586879730225
epoch 1 batch 74 loss 2.4160313606262207
epoch 1 batch 75 loss 2.3680434226989746
epoch 1 batch 76 loss 2.3533902168273926
epoch 1 batch 77 loss 2.3422646522521973
epoch 1 batch 78 loss 2.366873025894165
epoch 1 batch 79 loss 2.4485018253326416
epoch 1 batch 80 loss 2.4348983764648438
epoch 1 batch 81 loss 2.4048399925231934
epoch 1 batch 82 loss 2.3819291591644287
epoch 1 batch 83 loss 2.490535259246826
Traceback (most recent call last):
  File "/Users/oliverclive-griffin/personal/transformer-from-scratch/train.py", line 76, in <module>
    optimizer.step()
  File "/Users/oliverclive-griffin/.local/share/virtualenvs/transformer-from-scratch-IzBRPy8T/lib/python3.11/site-packages/torch/optim/lr_scheduler.py", line 69, in wrapper
    return wrapped(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/oliverclive-griffin/.local/share/virtualenvs/transformer-from-scratch-IzBRPy8T/lib/python3.11/site-packages/torch/optim/optimizer.py", line 280, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/oliverclive-griffin/.local/share/virtualenvs/transformer-from-scratch-IzBRPy8T/lib/python3.11/site-packages/torch/optim/optimizer.py", line 33, in _use_grad
    ret = func(self, *args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/oliverclive-griffin/.local/share/virtualenvs/transformer-from-scratch-IzBRPy8T/lib/python3.11/site-packages/torch/optim/adam.py", line 141, in step
    adam(
  File "/Users/oliverclive-griffin/.local/share/virtualenvs/transformer-from-scratch-IzBRPy8T/lib/python3.11/site-packages/torch/optim/adam.py", line 281, in adam
    func(params,
  File "/Users/oliverclive-griffin/.local/share/virtualenvs/transformer-from-scratch-IzBRPy8T/lib/python3.11/site-packages/torch/optim/adam.py", line 393, in _single_tensor_adam
    param.addcdiv_(exp_avg, denom, value=-step_size)
KeyboardInterrupt
epoch 1 batch 84 loss 2.444579601287842
epoch 1 batch 85 loss 2.4122233390808105
epoch 1 batch 86 loss 2.4118170738220215
epoch 1 batch 87 loss 2.3783507347106934
epoch 1 batch 88 loss 2.3889317512512207
epoch 1 batch 89 loss 2.3495774269104004
epoch 1 batch 90 loss 2.4401769638061523
epoch 1 batch 91 loss 2.380059242248535
epoch 1 batch 92 loss 2.3979086875915527
epoch 1 batch 93 loss 2.4546735286712646
epoch 1 batch 94 loss 2.4237141609191895
epoch 1 batch 95 loss 2.376735210418701
epoch 1 batch 96 loss 2.3719401359558105
epoch 1 batch 97 loss 2.3837594985961914
epoch 1 batch 98 loss 2.36466121673584
epoch 1 batch 99 loss 2.390894889831543
epoch 1 batch 100 loss 2.380643844604492